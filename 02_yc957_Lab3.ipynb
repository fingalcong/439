{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>Student Information</h3> Please provide information about yourself. We will NOT grade this submissing w/o all the information<br>\n",
    "<b>Name</b>:Yinfeng Cong<br>\n",
    "<b>NetID</b>:yc957<br>\n",
    "<b>Recitation (01,02,03)</b>:02<br>\n",
    "<b>Notes to Grader</b> (optional):<br>\n",
    "<br><br>\n",
    "<b>IMPORTANT</b>\n",
    "Your work will not be graded withour your initials below<br>\n",
    "I certify that this lab represents my own work and I have read the RU academic intergrity policies at<br>\n",
    "<a href=\"https://www.cs.rutgers.edu/academic-integrity/introduction\">https://www.cs.rutgers.edu/academic-integrity/introduction </a><br>\n",
    "<b>Initials</b>: YC     \n",
    "\n",
    "\n",
    "<h3>Grader Notes</h3>\n",
    "<b>Your Grade<b>:<br>\n",
    "<b>Grader Initials</b>:<br>\n",
    "<b>Grader Comments</b> (optional):<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## CS 439 - Introduction to Data Science\n",
    "### Spring 2022\n",
    "\n",
    "# Lab 3: Exploratary Data Analysis\n",
    "\n",
    "### Due Date: Thursday March 03, 2022 by 11:59 PM ###\n",
    "\n",
    "### Instructions\n",
    "This lab is presented as a notebook. Please execute the cells that are already completed and your task is to fill in the code\n",
    "between ### BEGIN SOLUTION ### and ### END SOLUTION ###. \n",
    "\n",
    "#### Important: Please do not add any new cells or change the order of cells. If you have questions, please contact the courseS staff.\n",
    "\n",
    "In this lab, you will be working with a dataset from NYPD containing data on calls to the New York Police Department. Information about the datasets can be found at https://opendata.cityofnewyork.us/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "setup",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "Note that after activating matplotlib to display figures inline via the IPython magic `%matplotlib inline`, we configure a custom default figure size. Virtually every default aspect of matplotlib [can be customized](https://matplotlib.org/users/customizing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "part1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Part 1:Getting Data\n",
    "\n",
    "We will work with the NYPD Historic complaint data set. Our first task is to estimate the size of this download by looking at the number of rows, columns and using an estimated size for a column (use a reasonable value). The site metadata is available from the page\n",
    "https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "estimated size of the download (based on metadata information from the site) =  2.3 GB     \n",
    "# please explain how you reached the answer\n",
    "#There are 21 columns with texts, data type is object, assuming 8 bytes for each data.\n",
    "#There are 10 columns with numbers, assuming 4 bytes for each data.\n",
    "#There are 3 columns with dates, assuming 8 bytes for each data.\n",
    "#There is 1 column with location, assuming 64 bytes for each data.\n",
    "#Total: 7370000*(10*4+21*8+3*8+1*64)/1000000000 = 2.182\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Download the data\n",
    "This file is large (use the estimate you did above). If it takes too long to download, you may want to interrupt and download the file using a browser and URL https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "download-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "data_dir = 'data'\n",
    "data_url = 'https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i'\n",
    "\n",
    "file_name = 'NYPD_Complaint_Data_Historic.csv'\n",
    "\n",
    "# To retrieve the dataset, we will use the `utils.fetch_and_cache` utility from utils library. \n",
    "dest_path = utils.fetch_and_cache(data_url=data_url, file=file_name,data_dir=data_dir)\n",
    "print(f'Located at {dest_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Inspect the size of the file\n",
    "It is helpful to get an idea of the size of the file. This can be done using functions in the utils library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q0",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# look at the size of the file w/o opening it using OS (https://docs.python.org/3/library/os.html). You can perform\n",
    "# variety of operating system related functions from this package.\n",
    "### BEGIN SOLUTION\n",
    "import os\n",
    "size = os.stat('data/NYPD_Complaint_Data_Historic.csv')\n",
    "size.st_size\n",
    "\n",
    "#### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Split the large file\n",
    "This data file NYPD_Complaint_Data_Historic.csv is too big to load into a single DataFrame. Let us split the large file into smaller files.  Let us find out the number of lines in the NYPD_Complaint_Data_Historic.csv file using utils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using utils library, find the number of lines in the file\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from utils import *\n",
    "linecount = line_count('data/NYPD_Complaint_Data_Historic.csv')\n",
    "linecount\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the file into 10 smaller files. Estimate the number of lines in each file using the count above\n",
    "# files should be created in the data folder and named NYPD_Complaint_Data_Historic_1.csv, \n",
    "# NYPD_Complaint_Data_Historic_2.csv, ... NYPD_Complaint_Data_Historic_10.csv etc\n",
    "# It is possible that few lines from the original file may not be saved due to rounding errors.\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "# obtain line number range for each sub-dataset\n",
    "sub_line_num = int(np.ceil(float(linecount) / 10)) # this way can bypass the rounding error and save everything\n",
    "\n",
    "# use iterator to write line by line, instead of reading large file to memory\n",
    "filename = 'data/NYPD_Complaint_Data_Historic.csv'\n",
    "for i in range(10):\n",
    "    with open(filename, \"r\") as f:\n",
    "        fw = open('data/NYPD_Complaint_Data_Historic_%d.csv' % (i+1), \"w\")\n",
    "       \n",
    "        sliced_f = itertools.islice(f, i*sub_line_num, min((i+1)*sub_line_num, linecount))  \n",
    "        # iterate through the sliced lines and write each line\n",
    "        for line in sliced_f:\n",
    "            fw.write(line)\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Check the files in the data folder\n",
    "Now, we'll use a method of the `Pathlib.Path` class called `glob` to list all files in the `data` directory. You will find useful information in pathlib [docs](https://docs.python.org/3/library/pathlib.html).\n",
    "\n",
    "Below, we use pathlib's `glob` method to store the list of all files' names from the `data_dir` directory in the variable `file_names`. These names should be strings that contain only the file name (e.g. `dummy.txt` not `data/dummy.txt`). The asterisk (*) character is used with the `glob` method to match any string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_dir_path = Path('data') # creates a Path object that points to the data directory\n",
    "file_names = [x.name for x in data_dir_path.glob('*') if x.is_file()]\n",
    "file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Pre-processing of data\n",
    "It is good to pre-process the data to see if the file can be opened in a Jupyter notebook. We need to avoid large files that can crash notebooks. Typically, files of size around 200 MB is ok to open into a DataFrame. In the following activities we will inspect the file w/o opening it as a DataFrame. Using utils.head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the util.head() to read up to 5 lines from the original file (w/o opening it)\n",
    "from utils import head\n",
    "head('data/NYPD_Complaint_Data_Historic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Inspecting and describing data columns\n",
    "There should be 35 columns in each record. Using header information and data types, describe the type of data in each\n",
    "column. If you are unable to determine, just state so.\n",
    "##### BEGIN SOLUTION\n",
    "* CMPLNT_NUM : number-integer\n",
    "* CMPLNT_FR_DT: Floating Timestamp-datetime\n",
    "* CMPLNT_FR_TM:Text-Object\n",
    "* CMPLNT_TO_DT:Floating Timestamp-datetime\n",
    "* CMPLNT_TO_TM:Text-Object\n",
    "* ADDR_PCT_CD:number-integer\n",
    "* RPT_DT:Timestamp-datetime\n",
    "* KY_CD: number-integer\n",
    "* OFNS_DESC:Text-Object\n",
    "* PD_CD: number-integer\n",
    "* PD_DESC: Text-Object\n",
    "* CRM_ATPT_CPTD_CD: Text-Object\n",
    "* LAW_CAT_CD: Text-Object\n",
    "* BORO_NM: Text-Object\n",
    "* LOC_OF_OCCUR_DESC: Text-Object\n",
    "* PREM_TYP_DESC: Text-Object\n",
    "* JURIS_DESC: Text-Object\n",
    "* JURISDICTION_CODE: number-integer\n",
    "* PARKS_NM: Text-Object\n",
    "* HADEVELOPT: Text-Object\n",
    "* HOUSING_PSA: Text-Object\n",
    "* X_COORD_CD: number-float\n",
    "* Y_COORD_CD: number-float\n",
    "* SUSP_AGE_GROUP: Text-Object\n",
    "* SUSP_RACE: Text-Object\n",
    "* SUSP_SEX: Text-Object\n",
    "* TRANSIT_DISTRICT: number-integer\n",
    "* Latitude: number-float\n",
    "* Longitude: number-float\n",
    "* Lat_Lon: location\n",
    "* PATROL_BORO: Text-Object\n",
    "* STATION_NAME: Text-Object\n",
    "* VIC_AGE_GROUP: Text-Object\n",
    "* VIC_RACE:Text-Object\n",
    "* VIC_SEX:Text-Object\n",
    "##### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "explore-0",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Part 2 - Exploratory Data Analysis\n",
    "Exploratory data analysis (EDA) is the process of examining a subest of a large data set to see what we can know about the data. First we will explore one file NYPD_Complaint_Data_Historic_1.csv to see what we can find out.\n",
    "\n",
    "### 2.1 Time to load dta into a DataFrame\n",
    "Load the first CSV file, NYPD_Complaint_Data_Historic_1.csv into a `pandas.DataFrame` object. Also do a time analysis to see how long it took to load the data into a DataFrame. Time should be printed in seconds. The time libraries https://docs.python.org/3/library/time.html can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "explore-1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "time_start=time.time()\n",
    "calls=pd.read_csv('data/NYPD_Complaint_Data_Historic_1.csv')\n",
    "time_end=time.time()\n",
    "print('time cost',time_end-time_start,'s')\n",
    "%memit pd.read_csv('data/NYPD_Complaint_Data_Historic_1.csv')\n",
    "calls.head()\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "explore-2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 2.2 Description of Fields\n",
    "Let's also check some basic information about these files using the `DataFrame.describe` and `DataFrame.info` methods. Describe columns that can be removed based on the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "explore-3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "calls.info()\n",
    "calls.describe()\n",
    "calls.columns[calls.isnull().mean() > 0.5].values\n",
    "# What columns can be removed from the DataFrame? A reasonable rule of thumb is that if a column is missing more than \n",
    "# 50% of the data then it should be removed\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "explore-4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 2.2 Finding Uniques\n",
    "\n",
    "Notice that the functions above reveal type information for the columns, as well as some basic statistics about the numerical columns found in the DataFrame. However, we still need more information about what each column represents. Let's explore the data further.\n",
    "\n",
    "find the number of unique values in each DataFrame column and answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "explore-5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "calls.nunique()\n",
    "\n",
    "# Questions\n",
    "# 1. How many distinct locations where the complaints have come from? - 77 (ADDR_PCT_CD)\n",
    "# 2. How many age groups are represented in the data set? - 25 (SUSP_AGE_GROUP)\n",
    "# 3. How many boroughs are included in the data set? - 5 (BORO_NM)\n",
    "# 4. How many offense types are listed in this data set? - 69 (KY_CD)\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Offense by Boro\n",
    "Using GroupBy operation, create a DataFrame that groups offenses by Boro. call the DataFrame calls_by_Boro_and_offense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "calls_by_Boro_and_offense = calls.groupby('BORO_NM').groups\n",
    "calls_by_Boro_and_offense\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 2.4 Offenses in Bronx\n",
    "\n",
    "In the cell below, find a list of strings corresponding to the possible values for `OFNS_DESC` when `BORO` is \"BRONX\". Create an expression that automatically extracts the names of the offenses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "calls_by_Boro_and_offense = calls.groupby('BORO_NM')['OFNS_DESC'].apply(pd.DataFrame)\n",
    "print(calls_by_Boro_and_offense['BRONX'].dropna().unique())\n",
    "\n",
    "calls_by_Boro_and_offense = calls.groupby('BORO_NM')\n",
    "print(len(calls_by_Boro_and_offense.get_group('BRONX')))\n",
    "\n",
    "### END SOLUTION\n",
    "\n",
    "# How many offenses were committed in Bronx during the analysis period?\n",
    "#160808"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 2.5 Most Common Crimes in NYC\n",
    "\n",
    "What are the five crime types of OFNS_DESC that have the most crime events in Bronx? You may need to use `value_counts` to find the answer. Save your results as a list of strings.\n",
    "\n",
    "**Hint:** *The `keys` method of the Series class might be useful.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "calls_by_Boro_and_offense = calls.groupby('BORO_NM')['OFNS_DESC'].apply(pd.DataFrame)\n",
    "calls_by_Boro_and_offense['BRONX'].value_counts().head(5).index.unique()\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Probability of a Crime in Bronx\n",
    "What is the probability that a the crime \"Arson\" can happen in Bronx?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q2-tests",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "p = calls_by_Boro_and_offense['BRONX'].value_counts()['ARSON']/calls_by_Boro_and_offense['BRONX'].count().sum()\n",
    "p\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "part2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "# Part 3: Visualizing the Data\n",
    "\n",
    "## Pandas vs. Seaborn Plotting\n",
    "\n",
    "Pandas offers basic functionality for plotting. For example, the `DataFrame` and `Series` classes both have a `plot` method. However, the basic plots generated by pandas are not particularly pretty. While it's possible to manually use matplotlib commands to make pandas plots look better, we'll instead use a high level plotting library called Seaborn that will take care of most of this for us.\n",
    "\n",
    "As you learn to do data visualization, you may find the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html) and [Seaborn documentation](https://seaborn.pydata.org/api.html) helpful!\n",
    "\n",
    "We will continue use EDA for examining a subest of a large data set to see what we can know about the data. Continue to explore one file NYPD_Complaint_Data_Historic_1.csv to see what we can find out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "plot-demo",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 3.1 Plotting a Series\n",
    "Using the built-in plotting functionality of pandas, such as `plot` method of the `Series` class to generate a `barh` plot type,  display the value counts for `OFNS_DESC` visually as a barh chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "plot-demo1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "calls_by_Boro_and_offense['BRONX'].value_counts().plot.barh()\n",
    "plt.xlabel('Number Of Calls')\n",
    "plt.ylabel('Crime Category')\n",
    "plt.title('Number Of Calls For Each Offense')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Getting a Better Plot\n",
    "The plot above can be messy as it plots all offenses. Plot only the offenses that has more than 10000 calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "calls_by_Boro_and_offense['BRONX'].value_counts()[calls_by_Boro_and_offense['BRONX'].value_counts()>10000].plot.barh()\n",
    "plt.xlabel('Number Of Calls')\n",
    "plt.ylabel('Crime Category')\n",
    "plt.title('Number of Calls By Crime Type')\n",
    "plt.show()\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "plot-demo2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "By contrast, the Seaborn library provides a specific function `countplot` built for plotting counts. It operates directly on the DataFrame itself i.e. there's no need to call `value_counts()` at all. This higher level approach makes it easier to work with. Use the y-label (\"Crime Category\"), x-label(\"Number of Calls\") and title_of_plot(\"Number of Calls By Crime Type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "plot-demo3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "plot = sns.countplot(y = 'OFNS_DESC', data=calls)\n",
    "\n",
    "plt.xlabel(\"Number of Calls\")\n",
    "plt.ylabel(\"Crime Category\")\n",
    "plt.title(\"Number of Calls By Crime Type\")\n",
    "plt.show()\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "plot-demo4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "You may note that the ordering might be different for the seaborn plot (as compared to pandas plot). If we want the same ordering that we had in the pandas plot, we can use the order parameter of the `countplot` method. It takes a list of strings corresponding to the axis to be ordered. By passing the index of the `value_counts`, you can get the order you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "plot-demo5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "plot = sns.countplot(y = 'OFNS_DESC',order = calls['OFNS_DESC'].value_counts(ascending = True).index, data=calls)\n",
    "\n",
    "plt.xlabel(\"Number of Calls\")\n",
    "plt.ylabel(\"Crime Category\")\n",
    "plt.title(\"Number of Calls By Crime Type\")\n",
    "plt.show()\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "plot-demo6",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now we have a pretty bar plot with the bars ordered by size. Though `seaborn` appears to provide a superior plot from a aesthetic point of view, the `pandas` plotting library is also good to understand. You'll get practice using both libraries in the following questions.\n",
    "\n",
    "## An Additional Note on Plotting in Jupyter Notebooks\n",
    "\n",
    "You may have noticed that many of our code cells involving plotting end with a semicolon (;). This prevents any extra output from the last line of the cell that we may not want to see. Try adding this to your own code in the following questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 3.3 making more plots\n",
    "\n",
    "Now it is your turn to make some more plots using `pandas` and `seaborn`. Let's start by looking at the distribution of calls over days of the week.\n",
    "\n",
    "The CMPLNT_FR_DT field contains the date of the event. We would like to add a new column to the DataFrame that includes Day of the week (DAY_OF_WEEK) that indicates the day of the week. This can help us analyze the crimes on a specific day of the week. For example, we can answer questions such as \"what day of the week that a LARSON is likely to happen in NYC?\"\n",
    "\n",
    "\n",
    "Add a new column `DAY_OF_WEEK` into the `calls` dataframe that has the day string (eg. 'Sunday') for the corresponding value in CMPLNT_FR_DT. For example, if the first 3 values of `CMPLNT_FR_DT` are `['01/27/2006, '01/28/2006, '01/29/2006]`, then the first 3 values of the `DAY_OF_WEEK` column should be `[\"Friday\", \"Saturday\", \"Sunday\"]`.\n",
    "\n",
    "**Hint:** *Try using the [Series.map](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.map.html) function on `calls[\"OFNS_DESC\"]`.  Can you assign this to the new column `calls[\"DAY_OF_WEEK\"]`?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "days = [\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"]\n",
    "### BEGIN SOLUTION\n",
    "date = pd.to_datetime(calls[\"CMPLNT_FR_DT\"], errors = 'coerce')\n",
    "week = date.dt.dayofweek\n",
    "DAY_OF_WEEK = week.map({0.0:'Monday',1.0:'Tuesday',2.0:'Wednesday',3.0:'Thursday',4.0:'Friday',5.0:'Saturday',6.0:'Sunday'})\n",
    "DAY_OF_WEEK.tolist()\n",
    "calls['DAY_OF_WEEK'] = DAY_OF_WEEK.tolist()\n",
    "calls\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 3.4 Seaborn plots\n",
    "\n",
    "Create a `seaborn` plot that shows the number of calls for each day of the week. You may want to use of the `rotation` argument in `ax.set_xticklabels`, which rotates the labels by 90 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b-ex",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "plot = sns.countplot(x ='DAY_OF_WEEK', data=calls,order = ['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday'])\n",
    "xlabels = [\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"]\n",
    "\n",
    "plot.set_xticklabels(labels = xlabels,rotation=90)\n",
    "plt.ylabel('Number Of Calls')\n",
    "plt.title('Number of Calls For Each Day of the Week')\n",
    "plt.show()\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b-instructions",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now, let's make the same plot using `pandas`. Construct a vertical bar plot with the count of the number of calls (entries in the table) for each day of the week **ordered by the day of the week** (eg. `Sunday`, `Monday`, ...). Do not use `sns` for this plot. Be sure that your axes are labeled and that your plot is titled.\n",
    "\n",
    "**Hint:** *Given a series `s`, and an array `coolIndex` that has the same entries as in `s.index`, `s[coolIndex]` will return a copy of the series in the same order as `coolIndex`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "calls['DAY_OF_WEEK'].value_counts().reindex([\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"]).plot.bar()\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Number Of Calls')\n",
    "plt.title('Number of Calls For Each Day of the Week')\n",
    "plt.show()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 3.5 What Day of the Week is more calls?\n",
    "\n",
    "Is it true that weekdays generally have slightly more calls than Saturday or Sunday? What can you say about the difference?\n",
    "\n",
    "##### BEGIN SOLUTION\n",
    "\n",
    "Yes, that can be say about most people prefer to saty at home for a rest in the weekend, and they need to go out for work during weekday. So there may have more probability in the weekday.\n",
    "\n",
    "##### END SOLUTION\n",
    "\n",
    "We can break down into some particular types of events to see their distribution. For example, let's make a bar plot for the OFNS_DESC \"HARRASSMENT 2\". Which day is the peak for \"HARRASSMENT 2\"?\n",
    "\n",
    "This time, use `seaborn` to create a vertical bar plot of the number of total noise violations reported on each day of the week, again ordered by the days of the week starting with Sunday. Do not use `pandas` to plot.\n",
    "\n",
    "**Hint:** *If you're stuck, use the code for the seaborn plot in above question as a starting point.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "plot = sns.countplot(x ='DAY_OF_WEEK', order = [\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"], data=calls[calls['OFNS_DESC'] == 'HARRASSMENT 2'])\n",
    "plt.xlabel('DAY_OF_WEEK')\n",
    "plot.set_xticklabels(labels = xlabels, rotation=90)\n",
    "plt.ylabel ('Number of Calls')\n",
    "plt.title('Number of Harrassment-2 Calls For Each Day of the Week' )\n",
    "plt.show()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 3.6 Distribution\n",
    "\n",
    "Do you see anything interesting about the distribution of HARRASSMENT 2 calls over a week? Type a short answer below.\n",
    "##### BEGIN SOLUTION\n",
    "HARRASSMENT 2 are less happen in the weekend, I guess they have weekend too, they don't have to work. So there may have more HARRASSMENT 2 in the weekday.\n",
    "##### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 3.7 More Plots\n",
    "\n",
    "Let's look at a similar distribution but for a crime we have much more calls data about. In the cell below, create the same plot as you did in previous questions, but now looking at instances of the OFNS_DESC \"BURGLARY\" (instead of \"HARRASSMENT 2\"). Use either `pandas` or `seaborn` plotting as you desire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q5-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "plot2 = sns.countplot(x ='DAY_OF_WEEK', order = [\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\"], data=calls[calls['OFNS_DESC'] == 'BURGLARY'])\n",
    "plt.xlabel ('DAY_OF_WEEK')\n",
    "plot2.set_xticklabels(labels = xlabels, rotation=90)\n",
    "plt.ylabel ('Number of Calls')\n",
    "plt.title('Number of BURGLARY Calls For Each Day of the Week' )\n",
    "plt.show()\n",
    "\n",
    "### END SOLUTION\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 3.8 time of events\n",
    "\n",
    "Now let's look at the CMPLNT_TO_TM column which indicates the time for events. Since it contains hour and minute information, let's extract the hour info and create a new column named `Hour` in the `calls` dataframe. You should save the hour as an `int`. Then plot the frequency of each hour in the table (i.e., `value_counts()`) sorted by the hour of the day (i.e., `sort_index()`).\n",
    "\n",
    "You will want to look into how to use:\n",
    "\n",
    "* [Series.str.slice](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.slice.html#pandas.Series.str.slice) to select the substring.\n",
    "* [Series.astype](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.astype.html) to change the type.\n",
    "\n",
    "**Hint:** *The `str` helper member of a series can be used to grab substrings.  For example, `calls[\"CMPLNT_TO_TM\"].str.slice(3,5)` returns the minute of each hour of the `CMPLNT_TO_TM`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls[\"Hour\"] = calls[\"CMPLNT_TO_TM\"].str.slice(0,2).replace(np.NaN,0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "calls['Hour'] = calls['CMPLNT_TO_TM'].str.slice(0,2).fillna(0).astype(int)\n",
    "calls['Hour'][calls['Hour']!= -1].value_counts().sort_index().plot.bar(figsize = (12,12))\n",
    "plt.xlabel ('Hour')\n",
    "plt.ylabel ('Number of Calls')\n",
    "plt.title('Number of Calls For per Hour' )\n",
    "plt.show() \n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "pandas-fraud-plot",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Create a pandas bar plot showing the number of BURGLARY crimes committed at each hour of the day. Use the labels\n",
    "* ax.set_xlabel(\"Hour of the Day\")\n",
    "* ax.set_ylabel(\"Number of Calls\")\n",
    "* ax.set_title(\"Number of Calls Reporting Fraud For Each Day of the Week\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "pandas-fraud-plot-code",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "\n",
    "x = calls['Hour'][(calls['Hour']!= -1)&(calls['OFNS_DESC'] == 'BURGLARY')].value_counts().sort_index().plot.bar()\n",
    "x.set_xlabel(\"Hour of the Day\")\n",
    "x.set_ylabel(\"Number of Calls\")\n",
    "x.set_title(\"Number of Calls Reporting Fraud For Each Day of the Week\")\n",
    "plt.show()\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 3.9 More plots\n",
    "\n",
    "In the cell below, create a seaborn plot of the same data. Again, make sure you provide axes labels and a title for your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "sns.countplot(x ='Hour', data=calls[(calls['Hour']!= -1)&(calls['OFNS_DESC'] == 'BURGLARY')])\n",
    "plt.xlabel(\"Hour of the Day\")\n",
    "plt.ylabel(\"Number of Calls\")\n",
    "plt.title(\"Number of Calls Reporting Fraud For Each Day of the Week\")\n",
    "plt.show()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### 3.10 Spike in burglary?\n",
    "\n",
    "According to your plots, is there a spike in calls reporting BURGLARY at any particular time? If so, Do you trust that this spike is legitimate, or could there be an issue with our data? Explain your reasoning in 1-2 sentences below.\n",
    "\n",
    "#### BEGIN SOLUTION\n",
    "Yes, becasue the peak of hour of the day is 7 and 17, these were the time people week up or come back to their home after work who just find that something wrong with their house and reporting fraud.\n",
    "\n",
    "#### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q7",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "In the cell below, we generate a boxplot which examines the hour of day of each crime broken down by the `OFNS_DESC` value.  To construct this plot we used the [DataFrame.boxplot](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.boxplot.html) documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q7-pandas-boxplot",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "calls.boxplot(column=\"Hour\", by='OFNS_DESC', rot=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q7-instructions",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "While the pandas boxplot is informative, we can use seaborn to create a more visually-appealing plot. Using seaborn, regenerate a better box plot. See either the textbook (https://www.textbook.ds100.org/ch/06/viz_quantitative.html) or the [seaborn boxplot documentation](https://seaborn.pydata.org/generated/seaborn.boxplot.html).\n",
    "\n",
    "Looking at your plot, which crime type appears to have the largest interquartile range? Put your results into `answer` as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q7-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Todo: Make a boxplot with seaborn\n",
    "### BEGIN SOLUTION\n",
    "ax = sns.boxplot(y = 'Hour', x = 'OFNS_DESC', data = calls)\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
    "ax.set_title(\"Distributions of Calls Over Hours in a Day, Grouped by Crime\");\n",
    "answer = \"Prostitution & related offenses ,Offense related to children, and Loitering/Gambling \"\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.11a Explore Suspect and Victim Age Relationships\n",
    "In this activity we explore relations between SUSP_AGE_GROUP and VIC_AGE_GROUP\n",
    "1. create a matrix of where rows are SUSP_AGE_GROUPS and Columns are VIC_AGE_GROUPs\n",
    "2. Fill in the matrix with all probabilities (eg. \"the probability that <18 susp_group target <18 victim_group). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "import numpy as np\n",
    "matrix = np.empty([5,5],dtype = float)\n",
    "M = calls.groupby('SUSP_AGE_GROUP')['VIC_AGE_GROUP'].apply(pd.DataFrame)\n",
    "a = M['<18'].value_counts()['<18']\n",
    "b = M['<18'].value_counts()['18-24']\n",
    "c = M['<18'].value_counts()['25-44']\n",
    "d = M['<18'].value_counts()['45-64']\n",
    "e = M['<18'].value_counts()['65+']\n",
    "f = M['18-24'].value_counts()['<18']\n",
    "g = M['18-24'].value_counts()['18-24']\n",
    "h = M['18-24'].value_counts()['25-44']\n",
    "i = M['18-24'].value_counts()['45-64']\n",
    "j = M['18-24'].value_counts()['65+']\n",
    "k = M['25-44'].value_counts()['<18']\n",
    "l = M['25-44'].value_counts()['18-24']\n",
    "m = M['25-44'].value_counts()['25-44']\n",
    "n = M['25-44'].value_counts()['45-64']\n",
    "o = M['25-44'].value_counts()['65+']\n",
    "p = M['45-64'].value_counts()['<18']\n",
    "q = M['45-64'].value_counts()['18-24']\n",
    "r = M['45-64'].value_counts()['25-44']\n",
    "s = M['45-64'].value_counts()['45-64']\n",
    "t = M['45-64'].value_counts()['65+']\n",
    "u = M['65+'].value_counts()['<18']\n",
    "v = M['65+'].value_counts()['18-24']\n",
    "w = M['65+'].value_counts()['25-44']\n",
    "x = M['65+'].value_counts()['45-64']\n",
    "y = M['65+'].value_counts()['65+']\n",
    "sum_of_age = a + b + c + d + e + f + g + h + i + j + k + l + m + n + o + p + q + r + s + t + u + v + w + x + y\n",
    "matrix[0][0] = a/sum_of_age * 100\n",
    "matrix[0][1] = b/sum_of_age * 100\n",
    "matrix[0][2] = c/sum_of_age * 100\n",
    "matrix[0][3] = d/sum_of_age * 100\n",
    "matrix[0][4] = e/sum_of_age * 100\n",
    "matrix[1][0] = f/sum_of_age * 100\n",
    "matrix[1][1] = g/sum_of_age * 100\n",
    "matrix[1][2] = h/sum_of_age * 100\n",
    "matrix[1][3] = i/sum_of_age * 100\n",
    "matrix[1][4] = j/sum_of_age * 100\n",
    "matrix[2][0] = k/sum_of_age * 100\n",
    "matrix[2][1] = l/sum_of_age * 100\n",
    "matrix[2][2] = m/sum_of_age * 100\n",
    "matrix[2][3] = n/sum_of_age * 100\n",
    "matrix[2][4] = o/sum_of_age * 100\n",
    "matrix[3][0] = p/sum_of_age * 100\n",
    "matrix[3][1] = q/sum_of_age * 100\n",
    "matrix[3][2] = r/sum_of_age * 100\n",
    "matrix[3][3] = s/sum_of_age * 100\n",
    "matrix[3][4] = t/sum_of_age * 100\n",
    "matrix[4][0] = u/sum_of_age * 100\n",
    "matrix[4][1] = v/sum_of_age * 100\n",
    "matrix[4][2] = w/sum_of_age * 100\n",
    "matrix[4][3] = x/sum_of_age * 100\n",
    "matrix[4][4] = y/sum_of_age * 100\n",
    "matrix\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.11b Explore Suspect and Victim Sex Relationships\n",
    "In this activity we explore relations between SUSP_SEX and VIC_SEX \n",
    "1. create a matrix of where rows are SUSP_SEX and Columns are VIC_SEX\n",
    "2. Fill in the matrix with all probabilities (eg. \"the probability that Males target other Males?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "import numpy as np\n",
    "a = np.empty([2,2],dtype = float)\n",
    "M = calls.groupby('SUSP_SEX')['VIC_SEX'].apply(pd.DataFrame)\n",
    "mm = M['M'].value_counts()['M']\n",
    "mf = M['M'].value_counts()['F']\n",
    "ff = M['F'].value_counts()['F']\n",
    "fm = M['F'].value_counts()['M']\n",
    "sum_of_race = mm + mf + ff + fm\n",
    "a[0][0] = mm/sum_of_race * 100\n",
    "a[0][1] = mf/sum_of_race * 100\n",
    "a[1][0] = fm/sum_of_race * 100\n",
    "a[1][1] = ff/sum_of_race * 100\n",
    "a\n",
    "\n",
    "#MF = calls.groupby('SUSP_SEX').get_group('M').groupby('VIC_SEX').get_group('F')\n",
    "#F = calls.groupby('SUSP_SEX').get_group('F').groupby('VIC_SEX').get_group('F')\n",
    "#FM = calls.groupby('SUSP_SEX').get_group('F').groupby('VIC_SEX').get_group('M')\n",
    "#M.value_counts()/F.value_counts()\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.11c Observations \n",
    "Based on what was calculated in 3.11a and 3.11b, state at least important observations.\n",
    "##### BEGIN SOLUTION\n",
    "It seems that SUSP that whose ages are 25-44 have the biggest vitim rate, and the VIC they choose is also 25-44.SUPS who are too old or too young have a low probability. (Young people have their parents, and old people have their children or they are too old to move)\n",
    "It seems that SUSP that whose race are male have a bigger probability, and the VIC they would like to choose most is female. The reason for this is that they think that females are more easily robbed I think.\n",
    "\n",
    "##### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.12 - Visualization of crimes on a Map of NYC\n",
    "Finally we attempt to visualize the crimes committed in NYC on a Map. For this activity, use all data, not just the First set,  NYPD_Complaint_Data_Historic_1. \n",
    "First we need to install some mapping software. RSun the cell below to install folium package for mapping software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buNYC = calls[calls[\"OFNS_DESC\"] == \"BURGLARY\"][:20]\n",
    "len(buNYC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the maps for BURGLARY in NYC\n",
    "### if it takes too much time or map does not show up, try plotting a subset of the data set of for a specific crime\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "import folium\n",
    "import json\n",
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/python-visualization/folium/master/examples/data'\n",
    "map1 = folium.Map(location=[40,-73], zoom_start=7)\n",
    "\n",
    "\n",
    "c = calls.dropna(subset=['Latitude', 'Longitude'])\n",
    "calls = c[c['OFNS_DESC'] == 'BURGLARY'].reset_index()\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    x = calls['Latitude'][i]\n",
    "    y = calls['Longitude'][i]\n",
    "\n",
    "    folium.Marker(\n",
    "        location=[x,y],\n",
    "        popup=folium.Popup(max_width=450).add_child(\n",
    "            folium.Vega(json.loads(requests.get(f'{url}/vis1.json').text), width=450, height=250))\n",
    "    ).add_to(map1)\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Congratulations !!!\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<h2>Submission Instructions</h2> \n",
    "<b> Output:</b> Please **remove all output** from your notebook prior to submission<br>\n",
    "<b> File Name:</b> Please name the file as your_section_your_netID_Lab3.ipynb (eg. 01_adg133_Lab3.ipynb<br>\n",
    "<b> Submit To: </b> Canvas &rarr; Assignments &rarr; Lab3 <br>\n",
    "<b>Warning:</b> Failure to follow directions may result in loss of points.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "finish",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "@2022 A.D. Gunawardena. Many people contributed to this lab including TA Liqin Long (now at Google). Much credits go to Josh Hug, and Berkeley Data Science Group for their contributions to the original version. Please DO NOT share this lab and/or post them on public sites."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
